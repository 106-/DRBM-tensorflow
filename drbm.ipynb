{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bittensorflow21venv439a957482134edc83be3578fd59c913",
   "display_name": "Python 3.6.2 64-bit ('tensorflow_2.1': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = 784\n",
    "hidden_num = 200\n",
    "output_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = math.sqrt(6/(input_num+hidden_num))\n",
    "w1 = tf.Variable(np.random.uniform(-limit, limit, (input_num, hidden_num)).astype(\"float32\"), name=\"w1\")\n",
    "limit = math.sqrt(6/(hidden_num+output_num))\n",
    "w2 = tf.Variable(np.random.uniform(-limit, limit, (hidden_num, output_num)).astype(\"float32\"), name=\"w2\")\n",
    "b1 = tf.Variable(np.zeros((hidden_num), dtype=\"float32\"), name=\"b1\")\n",
    "b2 = tf.Variable(np.zeros((output_num), dtype=\"float32\"), name=\"b2\")\n",
    "params = [b1, b2, w1, w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\")\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\")\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# return: (N, j, k)\n",
    "@tf.function\n",
    "def signal_all(input):\n",
    "    return tf.expand_dims(b1, 1) + w2 + tf.expand_dims(tf.matmul(input, w1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, j)\n",
    "# return: (N, j)\n",
    "#@tf.function\n",
    "#def activation(input):\n",
    "#    return tf.where(\n",
    "#        tf.math.abs(input) < 1e-5,\n",
    "#        np.log(2).astype(\"float32\") - input**2/6 + input**4/180,\n",
    "#        tf.math.log(2*tf.math.sinh(input)/input)\n",
    "#    )\n",
    "\n",
    "@tf.function\n",
    "def activation(input):\n",
    "    return tf.math.softplus(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# return: (N, k)\n",
    "@tf.function\n",
    "def probability(input):\n",
    "    energies = b2 + tf.reduce_sum(activation(signal_all(input)), 1)\n",
    "    max_energies = tf.reduce_max(energies, axis=1, keepdims=True)\n",
    "    return tf.nn.softmax(energies-max_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# output: (N, k)\n",
    "# return: (1)\n",
    "@tf.function\n",
    "def negative_log_likelihood(probs, labels):\n",
    "    single_prob = tf.reduce_sum(probs * labels, 1)\n",
    "    return -tf.reduce_mean(tf.math.log(single_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(input, labels, opt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(params)\n",
    "        predict_probs = probability(input)\n",
    "        loss = negative_log_likelihood(predict_probs, labels)\n",
    "    grads = tape.gradient(loss, params)\n",
    "    opt.apply_gradients(zip(grads, params))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predict_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test(input, labels):\n",
    "    predict_probs = probability(input)\n",
    "    loss = negative_log_likelihood(predict_probs, labels)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, predict_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1, Loss: 0.3761788308620453, Accuracy: 89.84833526611328, Test Loss: 0.22725063562393188, Test Accuracy: 93.4000015258789\nEpoch 2, Loss: 0.18691329658031464, Accuracy: 94.62000274658203, Test Loss: 0.1530020833015442, Test Accuracy: 95.42000579833984\nEpoch 3, Loss: 0.13151738047599792, Accuracy: 96.13500213623047, Test Loss: 0.11788664758205414, Test Accuracy: 96.51000213623047\nEpoch 4, Loss: 0.09818290174007416, Accuracy: 97.16500091552734, Test Loss: 0.10213764756917953, Test Accuracy: 96.93000030517578\nEpoch 5, Loss: 0.07615720480680466, Accuracy: 97.7933349609375, Test Loss: 0.08914702385663986, Test Accuracy: 97.1500015258789\nEpoch 6, Loss: 0.06026115268468857, Accuracy: 98.25, Test Loss: 0.078694187104702, Test Accuracy: 97.44999694824219\nEpoch 7, Loss: 0.04831394553184509, Accuracy: 98.64166259765625, Test Loss: 0.07368049025535583, Test Accuracy: 97.69999694824219\nEpoch 8, Loss: 0.03859495744109154, Accuracy: 98.94667053222656, Test Loss: 0.07162512838840485, Test Accuracy: 97.79999542236328\nEpoch 9, Loss: 0.030490970239043236, Accuracy: 99.22000122070312, Test Loss: 0.06974650919437408, Test Accuracy: 97.75\nEpoch 10, Loss: 0.024793416261672974, Accuracy: 99.40333557128906, Test Loss: 0.06751467287540436, Test Accuracy: 97.79000091552734\nEpoch 11, Loss: 0.02001640386879444, Accuracy: 99.5233383178711, Test Loss: 0.06770399957895279, Test Accuracy: 97.93000030517578\nEpoch 12, Loss: 0.015473093837499619, Accuracy: 99.72000122070312, Test Loss: 0.06825284659862518, Test Accuracy: 97.88999938964844\nEpoch 13, Loss: 0.012597774155437946, Accuracy: 99.7733383178711, Test Loss: 0.0728260800242424, Test Accuracy: 97.7199935913086\nEpoch 14, Loss: 0.009939447045326233, Accuracy: 99.84500122070312, Test Loss: 0.0675864964723587, Test Accuracy: 97.94999694824219\nEpoch 15, Loss: 0.008176603354513645, Accuracy: 99.87166595458984, Test Loss: 0.07203580439090729, Test Accuracy: 97.91999816894531\nEpoch 16, Loss: 0.0065716165117919445, Accuracy: 99.89833068847656, Test Loss: 0.07207972556352615, Test Accuracy: 97.86000061035156\nEpoch 17, Loss: 0.005121263675391674, Accuracy: 99.93000030517578, Test Loss: 0.0690368041396141, Test Accuracy: 97.98999786376953\nEpoch 18, Loss: 0.00393686955794692, Accuracy: 99.94999694824219, Test Loss: 0.07046830654144287, Test Accuracy: 97.93000030517578\nEpoch 19, Loss: 0.0032194466330111027, Accuracy: 99.97166442871094, Test Loss: 0.07698576897382736, Test Accuracy: 97.80999755859375\nEpoch 20, Loss: 0.002825008239597082, Accuracy: 99.96833038330078, Test Loss: 0.07282958179712296, Test Accuracy: 97.97000122070312\n"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train(images, labels, optimizer)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test(test_images, test_labels)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "  \n",
    "  # 次のエポック用にメトリクスをリセット\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  }
 ]
}