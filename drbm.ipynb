{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bittensorflow21venv439a957482134edc83be3578fd59c913",
   "display_name": "Python 3.6.2 64-bit ('tensorflow_2.1': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = 784\n",
    "hidden_num = 200\n",
    "output_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = math.sqrt(6/(input_num+hidden_num))\n",
    "w1 = tf.Variable(np.random.uniform(-limit, limit, (input_num, hidden_num)).astype(\"float32\"), name=\"w1\")\n",
    "limit = math.sqrt(6/(hidden_num+output_num))\n",
    "w2 = tf.Variable(np.random.uniform(-limit, limit, (hidden_num, output_num)).astype(\"float32\"), name=\"w2\")\n",
    "b1 = tf.Variable(np.zeros((hidden_num), dtype=\"float32\"), name=\"b1\")\n",
    "b2 = tf.Variable(np.zeros((output_num), dtype=\"float32\"), name=\"b2\")\n",
    "params = [b1, b2, w1, w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = (x_train / 255.0), x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\")\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\")\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(100)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# return: (N, j, k)\n",
    "@tf.function\n",
    "def signal_all(input):\n",
    "    return tf.expand_dims(b1, 1) + w2 + tf.expand_dims(tf.matmul(input, w1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha_j = c_j + U_jy + \\sum_{i} \\boldsymbol{W}_{j,i} \\boldsymbol{x_i}$ とすると, $\\sum_{h_j} \\exp(h_j \\alpha_j)$ は\n",
    "\n",
    "- 中間素子 $h_j$ が $h_j \\in \\left\\{ 0, 1 \\right\\}$ のとき\n",
    "\n",
    "$\\sum_{h_j} \\exp(h_j \\alpha_j) = \\ln (1+\\exp(x)) = \\mathrm{softplus}(x)$\n",
    "\n",
    "- 中間素子 $h_j$ が $h_j \\in \\left[ -1, +1 \\right]$ のとき\n",
    "\n",
    "$\\sum_{h_j} \\exp(h_j \\alpha_j) = \\ln \\frac{2 \\sinh(x)}{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, j)\n",
    "# return: (N, j)\n",
    "@tf.function\n",
    "@tf.custom_gradient\n",
    "def activation(input):\n",
    "    ret = tf.where(\n",
    "        tf.math.abs(input) < 1e-5,\n",
    "        tf.math.log(2.) + input**2/6,\n",
    "        tf.math.log(2*tf.math.sinh(input)/input)\n",
    "    )\n",
    "    @tf.function\n",
    "    def activation_grad(dy):\n",
    "        return tf.where(\n",
    "            input == 0,\n",
    "            0.,\n",
    "            dy * (1/tf.math.tanh(input) - 1/input)\n",
    "        )\n",
    "    return ret, activation_grad\n",
    "\n",
    "#@tf.function\n",
    "#def activation(input):\n",
    "#    return tf.math.softplus(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# return: (N, k)\n",
    "@tf.function\n",
    "def probability(input):\n",
    "    sig = tf.debugging.assert_all_finite( signal_all(input), \"signal_all\")\n",
    "    act = tf.debugging.assert_all_finite( activation(sig), \"activation\")\n",
    "    energies = b2 + tf.reduce_sum(act, 1)\n",
    "    max_energies = tf.reduce_max(energies, axis=1, keepdims=True)\n",
    "    return tf.nn.softmax(energies-max_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: (N, i)\n",
    "# output: (N, k)\n",
    "# return: (1)\n",
    "@tf.function\n",
    "def negative_log_likelihood(probs, labels):\n",
    "    single_prob = tf.reduce_sum(probs * labels, 1)\n",
    "    return -tf.reduce_mean(tf.math.log(single_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(input, labels, opt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(params)\n",
    "        predict_probs = probability(input)\n",
    "        loss = negative_log_likelihood(predict_probs, labels)\n",
    "    grads = tape.gradient(loss, params)\n",
    "    for g in grads:\n",
    "        tf.debugging.assert_all_finite(g, \"gradient\")\n",
    "    opt.apply_gradients(zip(grads, params))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predict_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test(input, labels):\n",
    "    predict_probs = probability(input)\n",
    "    loss = negative_log_likelihood(predict_probs, labels)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, predict_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1, Loss: 0.42067691683769226, Accuracy: 88.81999969482422, Test Loss: 0.26803818345069885, Test Accuracy: 92.1199951171875\nEpoch 2, Loss: 0.24803711473941803, Accuracy: 92.87833404541016, Test Loss: 0.2197519838809967, Test Accuracy: 93.63999938964844\nEpoch 3, Loss: 0.19857341051101685, Accuracy: 94.31499481201172, Test Loss: 0.17811623215675354, Test Accuracy: 94.7300033569336\nEpoch 4, Loss: 0.16230112314224243, Accuracy: 95.3800048828125, Test Loss: 0.15066532790660858, Test Accuracy: 95.47000122070312\nEpoch 5, Loss: 0.13512328267097473, Accuracy: 96.15166473388672, Test Loss: 0.13194890320301056, Test Accuracy: 96.17000579833984\nEpoch 6, Loss: 0.11457814276218414, Accuracy: 96.71666717529297, Test Loss: 0.11781653761863708, Test Accuracy: 96.6300048828125\nEpoch 7, Loss: 0.09817301481962204, Accuracy: 97.15166473388672, Test Loss: 0.11145833134651184, Test Accuracy: 96.62000274658203\nEpoch 8, Loss: 0.08391623198986053, Accuracy: 97.61166381835938, Test Loss: 0.09947498142719269, Test Accuracy: 96.83000183105469\nEpoch 9, Loss: 0.07316235452890396, Accuracy: 97.92832946777344, Test Loss: 0.09208600223064423, Test Accuracy: 97.19000244140625\nEpoch 10, Loss: 0.06367958337068558, Accuracy: 98.22666931152344, Test Loss: 0.08866856247186661, Test Accuracy: 97.31999969482422\nEpoch 11, Loss: 0.05589262768626213, Accuracy: 98.45500183105469, Test Loss: 0.08285914361476898, Test Accuracy: 97.5\nEpoch 12, Loss: 0.048867471516132355, Accuracy: 98.66500091552734, Test Loss: 0.08552885055541992, Test Accuracy: 97.3699951171875\nEpoch 13, Loss: 0.0431075282394886, Accuracy: 98.85166931152344, Test Loss: 0.08181123435497284, Test Accuracy: 97.43999481201172\nEpoch 14, Loss: 0.03754717856645584, Accuracy: 99.02999877929688, Test Loss: 0.07549174875020981, Test Accuracy: 97.64999389648438\nEpoch 15, Loss: 0.03272177651524544, Accuracy: 99.17166900634766, Test Loss: 0.07161492109298706, Test Accuracy: 97.68999481201172\nEpoch 16, Loss: 0.028554817661643028, Accuracy: 99.36000061035156, Test Loss: 0.0736566036939621, Test Accuracy: 97.5199966430664\nEpoch 17, Loss: 0.025308240205049515, Accuracy: 99.3933334350586, Test Loss: 0.06987430900335312, Test Accuracy: 97.75\nEpoch 18, Loss: 0.022017955780029297, Accuracy: 99.51499938964844, Test Loss: 0.07302048802375793, Test Accuracy: 97.80999755859375\nEpoch 19, Loss: 0.019317515194416046, Accuracy: 99.61833190917969, Test Loss: 0.07121745496988297, Test Accuracy: 97.7699966430664\nEpoch 20, Loss: 0.01667594723403454, Accuracy: 99.71333312988281, Test Loss: 0.06991443037986755, Test Accuracy: 97.95999908447266\n"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train(images, labels, optimizer)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test(test_images, test_labels)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "  \n",
    "  # 次のエポック用にメトリクスをリセット\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  }
 ]
}